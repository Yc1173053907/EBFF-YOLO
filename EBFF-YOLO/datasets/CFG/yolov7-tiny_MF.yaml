# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

#run
#python train.py --cfg E:\project_zhangzhen\SuperYOLO-improve\datasets\VEDAI\CFG\yolov7-tiny_MF.yaml --train_img_size 1024 --hr_input --data E:\project_zhangzhen\SuperYOLO-improve\datasets\VEDAI\CFG\SRvedai.yaml --ch 64 --input_mode RGB --batch_size 4

# anchors
anchors:
  - [12,16, 19,36, 40,28]  # P3/8
  - [36,75, 76,55, 72,146]  # P4/16
  - [142,110, 192,243, 459,401]  # P5/32

# yolov7 backbone
backbone:
  # [from, number, module, args]
  [
  # [-1, 1, Conv, [32, 3, 1]],  # 0
  
  #  [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2      
   [-1, 1, MF, [3]],
   [-1, 1, Conv, [64, 3, 1]],
   
   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4  
   [-1, 1, Yolov7_E_ELAN, [256, 64]], # 4
         
   [-1, 1, V7DownSampling, [128]],  # 5-P3/8  
   [-1, 1, Yolov7_E_ELAN, [512, 128]], # 6
         
   [-1, 1, V7DownSampling, [256]],  # 7-P4/16  
   [-1, 1, Yolov7_E_ELAN, [1024, 256]], # 8
         
   [-1, 1, V7DownSampling, [512]],  # 9-P5/32  
   [-1, 1, Yolov7_E_ELAN, [1024, 256]],  # 10
  ]

# yolov7 head
head:
  [[-1, 1, SPPCSPC, [512]], # 11

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [7, 1, Conv, [256, 1, 1]], # 14 route backbone P4
   [[-1, -2], 1, Concat, [1]], # 15
   
   [-1, 1, Yolov7_E_ELAN_NECK, [256, 128]], # 16
   
   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [5, 1, Conv, [128, 1, 1]], # 19 route backbone P3
   [[-1, -2], 1, Concat, [1]], # 20
   
   [-1, 1, Yolov7_E_ELAN_NECK, [128, 64]], # 21
      
   [[-1, 15], 1, V7DownSampling_Neck, [128]], # 22
   
   [-1, 1, Yolov7_E_ELAN_NECK, [256, 128]], # 23
      
   [[-1, 10], 1, V7DownSampling_Neck, [256]], # 24
   
   [-1, 1, Yolov7_E_ELAN_NECK, [512, 256]], # 25
   
   [20, 1, RepConv, [256, 3, 1]], # 26-P3
   [22, 1, RepConv, [512, 3, 1]], # 27-P4
   [24, 1, RepConv, [1024, 3, 1]], # 28-P5

   [[25, 26, 27], 1, IDetect, [nc, anchors]],   # Detect(P3, P4, P5)
  ]